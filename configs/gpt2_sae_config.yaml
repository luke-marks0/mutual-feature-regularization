experiment: gpt2-sae
epochs: 100
data_batch_size: 100
training_batch_size: 128
learning_rate: 0.001
input_size: 768
l1_coef: 0.005
hidden_size: 1536 
ar: False
beta: 5.0
num_saes: 1
property: 'x_hat'
